{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Logistic import sigmoid,compute_cost,compute_cost_reg,compute_gradient,compute_gradient_reg, gradient_descent\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data shape: (360, 64)\n",
      "Filtered target shape: (360,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "digits = load_digits()   \n",
    "\n",
    "data = digits.data\n",
    "target = digits.target\n",
    "\n",
    "# Filter for digits 0 and 1\n",
    "mask = np.isin(target, [0, 1])\n",
    "X = data[mask]\n",
    "y = target[mask]\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the result\n",
    "print(\"Filtered data shape:\", X.shape)\n",
    "print(\"Filtered target shape:\", y.shape)\n",
    "\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid([ -1, 0, 1, 2]) = [0.2689414213699951, 0.5, 0.7310585786300049, 0.8807970779778823]\n",
      "Cost at initial w and b (zeros): 0.693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value = 0\n",
    "\n",
    "print (f\"sigmoid({value}) = {sigmoid(value)}\")\n",
    "print (\"sigmoid([ -1, 0, 1, 2]) = \" + str(sigmoid(np.array([-1, 0, 1, 2]))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m, n = x_train.shape\n",
    "\n",
    "# Compute and display cost with w and b initialized to zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print('Cost at initial w and b (zeros): {:.3f}'.format(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at test w and b (non-zeros): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marianna\\Desktop\\ALL_the_algorithms_ML\\Logistic_regression\\Logistic.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -y[i]*(np.log(z)) - (1-y[i])*(np.log(1-z))\n",
      "c:\\Users\\Marianna\\Desktop\\ALL_the_algorithms_ML\\Logistic_regression\\Logistic.py:56: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  loss = -y[i]*(np.log(z)) - (1-y[i])*(np.log(1-z))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute and display cost with non-zero w and b\n",
    "test_w = np.full(n,0.2)\n",
    "test_b = -24.\n",
    "cost = compute_cost(x_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Cost at test w and b (non-zeros): {:.3f}'.format(cost))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w and b (zeros):0.5\n",
      "dj_dw at initial w and b (zeros):[728.6666666666666, 1.6666666666666667, 0.6666666666666666, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute and display gradient with w and b initialized to zeros\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "\n",
    "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db at initial w and b (zeros):{dj_db}' )\n",
    "print(f'dj_dw at initial w and b (zeros):{dj_dw.tolist()}' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at test w and b: 0.49652776992120995\n",
      "dj_dw at test w and b: [0.0, 0.013888888888883025, 2.1423611111083596, 6.496527691335197, 5.6597221515077445, 1.5277777777769819, 0.01736111111106112, 0.0, 0.0, 0.44444444444439596, 6.197916666665503, 6.656249913550707, 5.635416556663014, 5.718749999991081, 0.5312499999999212, 0.0, -2.6352377070616562e-15, 1.80555555555538, 7.072916666665218, 2.6701388024429846, 0.9722221200681229, 5.930555555551814, 1.8402777777775863, 0.0, -1.3176188535308281e-15, 2.565972222221925, 6.322916666659106, 1.0520832154979454, 0.05902767562552328, 4.420138888879275, 3.2638888888887174, 0.0, 0.0, 2.9652777777773105, 5.739583333328663, 0.45833323120147945, 0.02777767562426479, 4.340277777766174, 3.5659722222220305, 0.0, 0.0, 1.784722222222156, 6.5277777777745785, 0.8124998978606333, 0.791666595911374, 5.628472222214408, 2.874999999999846, 0.0, 0.0, 0.43749999999998634, 6.482638888886929, 4.895833254733868, 5.100694365847635, 6.527777777770173, 1.184027777777612, -1.5462939570751485e-14, 0.0, 0.003472222222221499, 2.1388888888882422, 6.736111040387551, 6.621527691333529, 2.743055555551265, 0.1493055555553262, -7.718517183421782e-14]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute and display cost and gradient with non-zero w and b\n",
    "test_w = np.full(n,0.2)\n",
    "test_b = -24\n",
    "dj_db, dj_dw  = compute_gradient(x_train, y_train, test_w, test_b)\n",
    "\n",
    "print('dj_db at test w and b:', dj_db)\n",
    "print('dj_dw at test w and b:', dj_dw.tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     2.59   \n",
      "Iteration 1000: Cost     0.01   \n",
      "Iteration 2000: Cost     0.00   \n",
      "Iteration 3000: Cost     0.00   \n",
      "Iteration 4000: Cost     0.00   \n",
      "Iteration 5000: Cost     0.00   \n",
      "Iteration 6000: Cost     0.00   \n",
      "Iteration 7000: Cost     0.00   \n",
      "Iteration 8000: Cost     0.00   \n",
      "Iteration 9000: Cost     0.00   \n",
      "Iteration 9999: Cost     0.00   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "initial_w = 0.01 * np.random.rand(x_train.shape[1])\n",
    "initial_b = -8\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_dy(w, b, x_train_train, y_train)\n",
    "# # Set the y-axis label\n",
    "# plt.ylabel('Exam 2 score') \n",
    "# # Set the x-axis label\n",
    "# plt.xlabel('Exam 1 score') \n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Test your predict code\n",
    "# np.random.seed(1)\n",
    "# tmp_w = np.random.randn(2)\n",
    "# tmp_b = 0.3    \n",
    "# tmp_X = np.random.randn(4, 2) - 0.5\n",
    "\n",
    "# tmp_p = predict(tmp_X, tmp_w, tmp_b)\n",
    "# print(f'Output of predict: shape {tmp_p.shape}, value {tmp_p}')\n",
    "\n",
    "\n",
    "# #Compute accuracy on our training set\n",
    "# p = predict(X_train, w,b)\n",
    "# print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
